{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AILearning10-5_preprocess&predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcJNVYHRSl2p2xA+76wjpi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nr6b4J_qx61",
        "outputId": "d50fff28-a93d-409a-e9dd-f78a6517d419"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUhjnPctrBLK"
      },
      "source": [
        "# Train MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7vAjt42q8d9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3mFtxZurBlC"
      },
      "source": [
        "### preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKfLP4Smrlu9"
      },
      "source": [
        "# load data\n",
        "X = pd.read_csv('X.csv')\n",
        "\n",
        "with open('y.npy', 'rb') as f:\n",
        "  y = np.load(f)\n",
        "  \n",
        "\n",
        "# select features\n",
        "\n",
        "# OverallQual 10\n",
        "# GrLivArea 10\n",
        "# GarageCars 9\n",
        "# GarageArea 8\n",
        "# TotalBsmtSF 7\n",
        "# 1stFlrSF 6\n",
        "# FullBath 5\n",
        "# LotShape Reg\n",
        "\n",
        "X = X[['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'LotShape_rank']]\n",
        "\n",
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(X)\n",
        "scaled_X = x_min_max_scaler.transform(X)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(y)\n",
        "scaled_y = y_min_max_scaler.transform(y)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Ht1e4-PX-p"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUR3CZR1PUvK",
        "outputId": "22214a6a-6c2a-484d-fc49-22521190e5b6"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=scaled_X.shape[-1]),\n",
        "        layers.Dense(96, activation='relu'),\n",
        "        layers.Dense(48, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ]\n",
        ")\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "model.fit(scaled_X, scaled_y,\n",
        "          batch_size=2, epochs=150,\n",
        "          callbacks=[early_stopping_callback], validation_split=0.05)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0051 - val_loss: 0.0090\n",
            "Epoch 2/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0037 - val_loss: 0.0017\n",
            "Epoch 3/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 4/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
            "Epoch 5/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0021\n",
            "Epoch 6/150\n",
            "694/694 [==============================] - 1s 965us/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 7/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 8/150\n",
            "694/694 [==============================] - 1s 977us/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 9/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0012\n",
            "Epoch 10/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 11/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0012\n",
            "Epoch 12/150\n",
            "694/694 [==============================] - 1s 969us/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 13/150\n",
            "694/694 [==============================] - 1s 988us/step - loss: 0.0023 - val_loss: 0.0012\n",
            "Epoch 14/150\n",
            "694/694 [==============================] - 1s 975us/step - loss: 0.0029 - val_loss: 0.0013\n",
            "Epoch 15/150\n",
            "694/694 [==============================] - 1s 998us/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 16/150\n",
            "694/694 [==============================] - 1s 961us/step - loss: 0.0022 - val_loss: 0.0013\n",
            "Epoch 17/150\n",
            "694/694 [==============================] - 1s 978us/step - loss: 0.0022 - val_loss: 0.0014\n",
            "Epoch 18/150\n",
            "694/694 [==============================] - 1s 991us/step - loss: 0.0025 - val_loss: 0.0012\n",
            "Epoch 19/150\n",
            "694/694 [==============================] - 1s 975us/step - loss: 0.0021 - val_loss: 0.0014\n",
            "Epoch 20/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 21/150\n",
            "694/694 [==============================] - 1s 986us/step - loss: 0.0022 - val_loss: 0.0013\n",
            "Epoch 22/150\n",
            "694/694 [==============================] - 1s 968us/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 23/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 24/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 0.0013\n",
            "Epoch 25/150\n",
            "694/694 [==============================] - 1s 990us/step - loss: 0.0023 - val_loss: 0.0012\n",
            "Epoch 26/150\n",
            "694/694 [==============================] - 1s 983us/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 27/150\n",
            "694/694 [==============================] - 1s 984us/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 28/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0011\n",
            "Epoch 29/150\n",
            "694/694 [==============================] - 1s 975us/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 30/150\n",
            "694/694 [==============================] - 1s 993us/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 31/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0014\n",
            "Epoch 32/150\n",
            "694/694 [==============================] - 1s 962us/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 33/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 34/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 35/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 36/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0039\n",
            "Epoch 37/150\n",
            "694/694 [==============================] - 1s 985us/step - loss: 0.0022 - val_loss: 0.0012\n",
            "Epoch 38/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 39/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 40/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 41/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 42/150\n",
            "694/694 [==============================] - 1s 972us/step - loss: 0.0019 - val_loss: 0.0011\n",
            "Epoch 43/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 44/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0019 - val_loss: 0.0014\n",
            "Epoch 45/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 46/150\n",
            "694/694 [==============================] - 1s 973us/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 47/150\n",
            "694/694 [==============================] - 1s 999us/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 48/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 49/150\n",
            "694/694 [==============================] - 1s 979us/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 50/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 51/150\n",
            "694/694 [==============================] - 1s 979us/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 52/150\n",
            "694/694 [==============================] - 1s 970us/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 53/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0013\n",
            "Epoch 54/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0017 - val_loss: 0.0013\n",
            "Epoch 55/150\n",
            "694/694 [==============================] - 1s 987us/step - loss: 0.0019 - val_loss: 0.0012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5b2b5f8210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUzU_GEZQcV6"
      },
      "source": [
        "pred = model.predict(scaled_X[:1])\n",
        "pred = y_min_max_scaler.inverse_transform(pred)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1S70_WaYssA"
      },
      "source": [
        "### Save MLP model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxHOmAj-YsgM"
      },
      "source": [
        "model.save(\"mlp_v0.1.h5\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhjGSM3sY08m"
      },
      "source": [
        "reconstructed_model = keras.models.load_model(\"mlp_v0.1.h5\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbEruB6cY05k"
      },
      "source": [
        "pred = reconstructed_model.predict(scaled_X[:1]) # 0 - 1\n",
        "pred = y_min_max_scaler.inverse_transform(pred)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1NyTJUbY03Q",
        "outputId": "0678a361-1a79-45d6-ba28-66898088feed"
      },
      "source": [
        "pred"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[189284.5]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZcm_VZgRGmZ"
      },
      "source": [
        "# Flask server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBF6beY72xUF",
        "outputId": "4497066b-56ae-4f44-d77e-e0661399e318"
      },
      "source": [
        "# Read data (v)\n",
        "# Preprocess data\n",
        "# Model prediction (v)\n",
        "# Return predict\n",
        "\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# load data\n",
        "X = pd.read_csv('X.csv')\n",
        "\n",
        "with open('y.npy', 'rb') as f:\n",
        "  y = np.load(f)\n",
        "\n",
        "# OverallQual 10\n",
        "# GrLivArea 10\n",
        "# GarageCars 9\n",
        "# GarageArea 8\n",
        "# TotalBsmtSF 7\n",
        "# 1stFlrSF 6\n",
        "# FullBath 5\n",
        "# LotShape Reg\n",
        "X = X[['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'LotShape_rank']]\n",
        "\n",
        "# 우리가 모델을 띄울 때 항상 학습을 시키지 않을 것이기 때문에\n",
        "# 모델과 min max scaler는 Flask 서버가 실행될 때 바로 로딩할 수 있는 상태가 되어야 한다.\n",
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(X)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(y)\n",
        "\n",
        "# load model\n",
        "reconstructed_model = keras.models.load_model(\"mlp_v0.1.h5\")\n",
        "\n",
        "\n",
        "# run server\n",
        "app = Flask(__name__, template_folder='/content')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "def preprocess_data(data):\n",
        "  # TODO: 전처리\n",
        "\n",
        "  '''\n",
        "  Dictionary --> np array (1, 8)\n",
        "\n",
        "  OverallQual 2\n",
        "  GrLivArea 5000\n",
        "  GarageCars 2\n",
        "  GarageArea 480\n",
        "  TotalBsmtSF 991\n",
        "  1stFlrSF 1087\n",
        "  FullBath 2\n",
        "  LotShape IR3\n",
        "  '''\n",
        "  \n",
        "  # Scale normalizaion\n",
        "  X = []  # <-- OverallQual, GrLivArea, ..., LotShape\n",
        "  for k, v in data.items():\n",
        "    if k == 'LotShape':\n",
        "      if v == 'Reg':\n",
        "        X.append(4)\n",
        "      elif v == 'IR1':\n",
        "        X.append(3)\n",
        "      elif v == 'IR2':\n",
        "        X.append(2)\n",
        "      elif v == 'IR3':\n",
        "        X.append(1)\n",
        "    else:\n",
        "      X.append(float(v))\n",
        "  \n",
        "  # X = [2, 5000, 2, ..., 3]\n",
        "  X = np.array(X) # (8, )\n",
        "  X = X.reshape((1, -1)) # (1, 8)\n",
        "\n",
        "  # min max scaling\n",
        "  scaled_X = x_min_max_scaler.transform(X)\n",
        "\n",
        "  #return np.zeros((1, 8)) # dummy data\n",
        "  return scaled_X\n",
        "\n",
        "@app.route(\"/\")\n",
        "def predict():\n",
        "  # return \"<h1>This is your Flask server.</h1>\"\n",
        "  return render_template(\"submit_form.html\")\n",
        "\n",
        "@app.route(\"/result\", methods=['POST'])\n",
        "def result():\n",
        "  data = request.form # User data\n",
        "\n",
        "  message = \"\"\n",
        "  message += \"<h1>House Price</h1>\"\n",
        "\n",
        "  for k, v in data.items():\n",
        "    print(k, v)\n",
        "    message += k + \": \" + v + \"</br>\"\n",
        "  \n",
        "  # 데이터 전처리\n",
        "  X = preprocess_data(data) # User data --> (1, 8) array\n",
        "\n",
        "  pred = reconstructed_model.predict(X)\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)\n",
        "  # array (1, 1) --> string\n",
        "\n",
        "  message += \"</br>\"\n",
        "  message += \"Predicted price: \" + str(pred[0][0])\n",
        "\n",
        "  return message\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://8c7f94f8e450.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [11/Aug/2021 04:16:14] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [11/Aug/2021 04:16:14] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [11/Aug/2021 04:16:15] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [11/Aug/2021 04:16:15] \"\u001b[37mPOST /result HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OverallQual 6\n",
            "GrLivArea 1464\n",
            "GarageCars 2\n",
            "GarageArea 480\n",
            "TotalBsmtSF 991\n",
            "1stFlrSF 1087\n",
            "FullBath 2\n",
            "LotShape IR1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [11/Aug/2021 04:16:17] \"\u001b[31m\u001b[1mGET /result HTTP/1.1\u001b[0m\" 405 -\n",
            "127.0.0.1 - - [11/Aug/2021 04:16:33] \"\u001b[37mPOST /result HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OverallQual 10\n",
            "GrLivArea 1508\n",
            "GarageCars 0\n",
            "GarageArea 480\n",
            "TotalBsmtSF 970\n",
            "1stFlrSF 1114\n",
            "FullBath 2\n",
            "LotShape IR2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}