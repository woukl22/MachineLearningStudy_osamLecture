{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AILearning09-1_Hyperparameter Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMn9/gefe2wpd3f1lMX7X9q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xHX-voxl5Yx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rSublgLmFYj"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYIGwbRamO01"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm6D0D-AmVPt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5EvTyeZmZlF"
      },
      "source": [
        "with open('X.npy', 'rb') as f:\n",
        "  X = np.load(f)\n",
        "\n",
        "with open('y.npy', 'rb') as f:\n",
        "  y = np.load(f)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opSk7F-TmjVV",
        "outputId": "899be54c-3d54-4b73-b073-417f09cf3dbd"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1460, 60), (1460, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8fkp04DmlW3"
      },
      "source": [
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(X)\n",
        "scaled_X = x_min_max_scaler.transform(X)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(y)\n",
        "scaled_y = y_min_max_scaler.transform(y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZXCqxldmxTF"
      },
      "source": [
        "# K-fold cross validation\n",
        "K = 10\n",
        "kf = KFold(n_splits=K)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEJ73o1KnBSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66531a86-73d3-4659-fb49-36d79905c4db"
      },
      "source": [
        "rmses = []\n",
        "for train_index, test_index in kf.split(scaled_X):\n",
        "  scaled_X_train, scaled_X_test = scaled_X[train_index], scaled_X[test_index]\n",
        "  scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  # training\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "        keras.Input(shape=scaled_X_train.shape[-1]),\n",
        "        layers.Dense(96, activation='relu'),\n",
        "        layers.Dense(48, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.005)\n",
        "  model.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "  early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n",
        "  model.fit(scaled_X_train, scaled_y_train,\n",
        "                    batch_size=1, epochs=150,\n",
        "                    callbacks=[early_stopping_callback], validation_split=0.05, verbose='auto')\n",
        "\n",
        "  # evaluation\n",
        "  pred = model.predict(scaled_X_test).reshape((-1, 1))\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
        "\n",
        "  print(rmse)\n",
        "  print(\"--------------\")\n",
        "  \n",
        "\n",
        "  rmses.append(rmse)\n",
        "\n",
        "print(\"average rmse:\", np.mean(rmses))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0073 - val_loss: 0.0027\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0048 - val_loss: 0.0022\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0039 - val_loss: 0.0144\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0046 - val_loss: 0.0017\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0034 - val_loss: 0.0028\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 0.0017\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0029 - val_loss: 0.0045\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 11/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 12/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 13/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0019 - val_loss: 0.0040\n",
            "41616.24679769574\n",
            "--------------\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0083 - val_loss: 0.0030\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0061 - val_loss: 0.0038\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 0.0017\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0032 - val_loss: 0.0017\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0042 - val_loss: 0.0053\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 0.0017\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 0.0040\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 0.0031\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 0.0015\n",
            "Epoch 11/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0041\n",
            "Epoch 12/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
            "Epoch 13/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 14/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 15/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 16/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 17/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "31077.81735514029\n",
            "--------------\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0079 - val_loss: 0.0053\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0052 - val_loss: 0.0026\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0042 - val_loss: 0.0018\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0039 - val_loss: 0.0017\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 0.0017\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 11/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 12/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 13/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "28365.328693905765\n",
            "--------------\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0062 - val_loss: 0.0033\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0057 - val_loss: 0.0018\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0034 - val_loss: 0.0021\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0070 - val_loss: 0.0057\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0047 - val_loss: 0.0017\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0031 - val_loss: 0.0018\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0030 - val_loss: 0.0026\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 0.0017\n",
            "Epoch 11/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0027 - val_loss: 0.0021\n",
            "Epoch 12/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0030 - val_loss: 0.0018\n",
            "Epoch 13/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
            "40228.27375935791\n",
            "--------------\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0058 - val_loss: 0.0050\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0052 - val_loss: 0.0019\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0040\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0013\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 11/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 12/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 13/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 14/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0014\n",
            "Epoch 15/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 16/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 17/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 18/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 19/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 20/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "43995.42900177928\n",
            "--------------\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0078 - val_loss: 0.0017\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0048 - val_loss: 0.0028\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0050 - val_loss: 0.0021\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0061 - val_loss: 0.0047\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0043 - val_loss: 0.0030\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 0.0027\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 0.0015\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0029 - val_loss: 0.0015\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 11/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0011\n",
            "Epoch 12/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 13/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 14/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 15/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0033 - val_loss: 0.0017\n",
            "Epoch 16/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0030 - val_loss: 0.0018\n",
            "Epoch 17/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "Epoch 18/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
            "32940.11069176729\n",
            "--------------\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 6s 4ms/step - loss: 0.0083 - val_loss: 0.0076\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0049 - val_loss: 0.0019\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0052 - val_loss: 0.0036\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0039 - val_loss: 0.0016\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0038 - val_loss: 0.0028\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0036 - val_loss: 0.0033\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0031 - val_loss: 0.0021\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 11/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "33327.94059688472\n",
            "--------------\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0070 - val_loss: 0.0016\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0047 - val_loss: 0.0101\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0053 - val_loss: 0.0031\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0037 - val_loss: 0.0029\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "39821.90041274874\n",
            "--------------\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0056 - val_loss: 0.0033\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0033 - val_loss: 0.0024\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0021\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0012\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0033\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0025 - val_loss: 0.0013\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0027 - val_loss: 0.0013\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0025 - val_loss: 0.0012\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 11/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 12/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 13/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 14/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0021\n",
            "Epoch 15/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0022 - val_loss: 0.0016\n",
            "62209.791241665676\n",
            "--------------\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0069 - val_loss: 0.0153\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 0.0054\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0029 - val_loss: 0.0464\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0030 - val_loss: 0.0276\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 0.0200\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0258\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0030 - val_loss: 0.0206\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0214\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0334\n",
            "41531.10318930409\n",
            "--------------\n",
            "average rmse: 39511.39417402495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDaq-6EqnoXL"
      },
      "source": [
        "# Hyperparameter\n",
        "- batch size\n",
        "- learning rate\n",
        "- number of layers\n",
        "- feature sizes\n",
        "- activation functions\n",
        "- optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuM6zjbFtX-j"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8vyDOjZm1tt"
      },
      "source": [
        "batch_sizes = np.arange(5, 10, 2) # batch size는 5에서부터 10까지 2칸씩 띄어가면서 탐색하고 싶음."
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsCv8nAotcc2",
        "outputId": "8dcfe07f-77c6-4b94-c715-446ea6c39ec6"
      },
      "source": [
        "batch_sizes"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 7, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca9fMMdZtdZ9"
      },
      "source": [
        "learning_rates = [0.005, 0.01, 0.02]  # learning rate는 0.005, 0.01, 0.02를 탐색할 것"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3woajidWw2gU",
        "outputId": "3a1faf14-7855-400c-96ae-8ae72c82c3fb"
      },
      "source": [
        "# 총 9개의 세트가 나온다.\n",
        "# 여기서 최적의 rmse값이 나오는 hyperparameter set을 골라내면 hyperparameter tuning을 했다고 할 수 있다.\n",
        "for batch_size in batch_sizes:\n",
        "  for learning_rate in learning_rates:\n",
        "    print(\"batch_size:\", batch_size, \"learning_rate:\", learning_rate)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_size: 5 learning_rate: 0.005\n",
            "batch_size: 5 learning_rate: 0.01\n",
            "batch_size: 5 learning_rate: 0.02\n",
            "batch_size: 7 learning_rate: 0.005\n",
            "batch_size: 7 learning_rate: 0.01\n",
            "batch_size: 7 learning_rate: 0.02\n",
            "batch_size: 9 learning_rate: 0.005\n",
            "batch_size: 9 learning_rate: 0.01\n",
            "batch_size: 9 learning_rate: 0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Hkmo6gthSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06e23ec-ba2b-4bfa-b098-6c3a5ba3017d"
      },
      "source": [
        "results = []\n",
        "for batch_size in batch_sizes:\n",
        "  for learning_rate in learning_rates:\n",
        "    print(batch_size, learning_rate)\n",
        "    for train_index, test_index in kf.split(scaled_X):\n",
        "      scaled_X_train, scaled_X_test = scaled_X[train_index], scaled_X[test_index]\n",
        "      scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n",
        "      y_test = y[test_index]\n",
        "\n",
        "      # training\n",
        "      model = keras.Sequential(\n",
        "          [\n",
        "            layers.InputLayer(input_shape=scaled_X_train.shape[-1]),\n",
        "            layers.Dense(96, activation='relu'),\n",
        "            layers.Dense(48, activation='relu'),\n",
        "            layers.Dense(1)\n",
        "          ]\n",
        "      )\n",
        "\n",
        "      # model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "      opt = keras.optimizers.Adam(learning_rate=0.005)\n",
        "      model.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "      early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n",
        "      model.fit(scaled_X_train, scaled_y_train,\n",
        "                        batch_size=1, epochs=150,\n",
        "                        callbacks=[early_stopping_callback], validation_split=0.05, verbose='auto')\n",
        "\n",
        "      # evaluation\n",
        "      pred = model.predict(scaled_X_test).reshape((-1, 1))\n",
        "      pred = y_min_max_scaler.inverse_transform(pred)\n",
        "      rmse = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
        "\n",
        "      print(rmse)\n",
        "      print(\"--------------\")\n",
        "\n",
        "      result = {}\n",
        "      result['batch_size'] = batch_size\n",
        "      result['learning_rate'] = learning_rate\n",
        "      result['rmse'] = rmse\n",
        "\n",
        "      results.append(result)\n",
        "      break\n",
        "  break"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 0.005\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0069 - val_loss: 0.0020\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0045 - val_loss: 0.0016\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0043 - val_loss: 0.0020\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0043 - val_loss: 0.0020\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0030 - val_loss: 0.0068\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0028 - val_loss: 0.0017\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0032 - val_loss: 0.0018\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0104\n",
            "71074.86494270364\n",
            "--------------\n",
            "5 0.01\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 85s 1ms/step - loss: 0.0082 - val_loss: 0.0016\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0054 - val_loss: 0.0032\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0060 - val_loss: 0.0015\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0032 - val_loss: 0.0037\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0032 - val_loss: 0.0027\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0031 - val_loss: 0.0019\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0030 - val_loss: 0.0023\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "24298.06777689446\n",
            "--------------\n",
            "5 0.02\n",
            "Epoch 1/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0065 - val_loss: 0.0020\n",
            "Epoch 2/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0049 - val_loss: 0.0020\n",
            "Epoch 3/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0039 - val_loss: 0.0017\n",
            "Epoch 4/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0039 - val_loss: 0.0017\n",
            "Epoch 5/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0041 - val_loss: 0.0017\n",
            "Epoch 6/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 7/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
            "Epoch 8/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 9/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 10/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
            "Epoch 11/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0014\n",
            "Epoch 12/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 13/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 14/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 15/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 16/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0025 - val_loss: 0.0017\n",
            "Epoch 17/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0019 - val_loss: 0.0029\n",
            "Epoch 18/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 19/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
            "Epoch 20/150\n",
            "1248/1248 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "36822.160466083864\n",
            "--------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST4k6HaFzDjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743a055b-cc43-4875-eb03-d9325214c97a"
      },
      "source": [
        "results"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'batch_size': 5, 'learning_rate': 0.005, 'rmse': 71074.86494270364},\n",
              " {'batch_size': 5, 'learning_rate': 0.01, 'rmse': 24298.06777689446},\n",
              " {'batch_size': 5, 'learning_rate': 0.02, 'rmse': 36822.160466083864}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OqeE34WzFhd"
      },
      "source": [
        "# Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9TzrOVOzKlM"
      },
      "source": [
        "# grid search에서는 범위를 어떤 룰에 의해 만들었다면, \n",
        "# random search는 시작과 끝점만 정해주고, 그 사이에서 랜덤으로 값을 뽑아오게 된다.\n",
        "import random"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r58iuuIzNUC"
      },
      "source": [
        "batch_sizes = random.sample(range(1, 11), 5)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCjf0bbtzQRO",
        "outputId": "be9225bb-5812-4767-bddf-f8e45bcc6cf3"
      },
      "source": [
        "batch_sizes"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 5, 7, 6, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiIvUVErzRUW"
      },
      "source": [
        "learning_rates = np.random.uniform(low=0.005, high=0.1, size=(4,))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPzG-SXFzWQ9",
        "outputId": "1c972031-d3ad-4ecd-f2ec-321f54444de3"
      },
      "source": [
        "# 정말 상상도 못했던 숫자에서 최적의 값이 나올 수 있음!\n",
        "learning_rates"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0122374 , 0.08654849, 0.037508  , 0.09966664])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52u-J4AwzXIs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}